{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBbC4vlK7Hyb"
      },
      "source": [
        "# Bab 9 Extreme Learning Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WjSkbk57Hlf"
      },
      "source": [
        "## Praktikum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RduxLPzY7HaP"
      },
      "source": [
        "### a) Fungsi *Training* ELM\n",
        "\n",
        "Tulis kode ke dalam *cell* di bawah ini:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6M5D3hy6_YT"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def elm_fit(X, target, h, W=None):\n",
        "    start_time = time.time()\n",
        "\n",
        "    if W is None:\n",
        "        W = np.random.uniform(-.1, .1, (h, len(X[0])))\n",
        "\n",
        "    Hinit = X @ W.T\n",
        "    H = 1 / (1 + np.exp(-Hinit))\n",
        "    Ht = H.T\n",
        "    Hp = np.linalg.inv(Ht @ H) @ Ht\n",
        "    beta = Hp @ target\n",
        "    y = H @ beta\n",
        "    mape = sum(abs(y - target) / target) * 100 / len(target)\n",
        "\n",
        "    execution = time.time() - start_time\n",
        "    print(\"Waktu eksekusi: %s detik\" % execution)\n",
        "\n",
        "    return W, beta, mape"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPmJcJpY7XpN"
      },
      "source": [
        "### b) Fungsi *Testing* ELM\n",
        "\n",
        "Tulis kode ke dalam *cell* di bawah ini:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38sj5oIK7YAj"
      },
      "source": [
        "def elm_predict(X, W, b, round_output=False):\n",
        "    Hinit = X @ W.T\n",
        "    H = 1 / (1 + np.exp(-Hinit))\n",
        "    y = H @ b\n",
        "\n",
        "    if round_output:\n",
        "        y = [int(round(x)) for x in y]\n",
        "    return y"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INz910K1VLRD"
      },
      "source": [
        "### c) Klasifikasi *Dataset* Iris\n",
        "\n",
        "![Iris Dataset](https://www.spataru.at/images/blog/iris-dataset-svm/iris_types.jpg)\n",
        "\n",
        "Tulis kode ke dalam *cell* di bawah ini:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SilFnskvVLlr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b4a29f-f959-47ce-fcb6-c73e503bafd9"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = minmax_scale(iris.data)\n",
        "Y = iris.target\n",
        "Y += 1\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.3)\n",
        "\n",
        "W, b, mape = elm_fit(X_train, y_train, 3)\n",
        "print('MAPE:', mape)\n",
        "output = elm_predict(X_test, W, b, round_output=True)\n",
        "accuracy = accuracy_score(output, y_test)\n",
        "\n",
        "print('Output:', output)\n",
        "print('True :', y_test)\n",
        "print('Accuracy:', accuracy)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waktu eksekusi: 0.0002734661102294922 detik\n",
            "MAPE: 8.602051421386658\n",
            "Output: [2, 2, 3, 2, 2, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 3, 1, 1, 1, 2, 3, 1, 1, 3, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 2, 2, 3, 2, 1, 1, 1]\n",
            "True : [2 2 3 2 2 2 3 1 1 2 3 1 2 3 1 1 2 3 3 1 1 1 2 3 1 1 3 3 1 3 1 2 3 1 2 3 1\n",
            " 2 2 2 3 2 1 1 1]\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analisis\n"
      ],
      "metadata": {
        "id": "BXBHeZqkTTV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Lakukan klasifikasi dengan menggunakan dataset Iris seperti pada contoh di atas. Ubahlah nilai pengaturan sebagai berikut:\n",
        "\n",
        "*   Rasio data latih: 70% dan data uji: 30%\n",
        "*   Jumlah hidden neuron: 3;5;7;10;30\n",
        "\n",
        "Lakukanlah pengujian menggunakan jumlah hidden hidden neuron yang berbeda dan bandingkan hasilnya. Analisa kemampuan algoritma ELM untuk mengklasifikasikan dataset Iris tersebut.\n"
      ],
      "metadata": {
        "id": "Y8UHEcH1TkCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.3)\n",
        "\n",
        "hidden_neurons = [3, 5, 7, 10, 30]\n",
        "\n",
        "for neurons in hidden_neurons:\n",
        "    W, b, mape = elm_fit(X_train, y_train, neurons)\n",
        "    print(f'Hidden Neurons: {neurons}, MAPE: {mape}')\n",
        "\n",
        "    output = elm_predict(X_test, W, b, round_output=True)\n",
        "    accuracy = accuracy_score(output, y_test)\n",
        "\n",
        "    print('Output:', output)\n",
        "    print('True :', y_test)\n",
        "    print(f'Accuracy with {neurons} hidden neurons:', accuracy)\n",
        "    print('-' * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyUCgQcpTwDu",
        "outputId": "8ef3b0d9-c2a4-40b9-b981-98cbe03c0340"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waktu eksekusi: 0.0002789497375488281 detik\n",
            "Hidden Neurons: 3, MAPE: 12.03456728188226\n",
            "Output: [2, 2, 1, 3, 2, 2, 1, 3, 1, 2, 3, 1, 2, 2, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 2, 1, 3, 3, 1, 1, 2, 1, 2, 3, 3, 2, 1, 1]\n",
            "True : [2 2 1 3 2 2 1 3 1 2 3 1 2 2 1 1 1 2 3 3 3 1 1 1 1 3 3 3 1 1 1 2 1 3 3 1 1\n",
            " 2 1 2 3 3 2 1 1]\n",
            "Accuracy with 3 hidden neurons: 1.0\n",
            "--------------------------------------------------\n",
            "Waktu eksekusi: 0.00047707557678222656 detik\n",
            "Hidden Neurons: 5, MAPE: 8.6935336166337\n",
            "Output: [2, 2, 1, 3, 2, 2, 1, 3, 1, 2, 3, 1, 2, 2, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 2, 1, 3, 2, 1, 1, 2, 1, 2, 3, 3, 2, 1, 1]\n",
            "True : [2 2 1 3 2 2 1 3 1 2 3 1 2 2 1 1 1 2 3 3 3 1 1 1 1 3 3 3 1 1 1 2 1 3 3 1 1\n",
            " 2 1 2 3 3 2 1 1]\n",
            "Accuracy with 5 hidden neurons: 0.9777777777777777\n",
            "--------------------------------------------------\n",
            "Waktu eksekusi: 0.003362417221069336 detik\n",
            "Hidden Neurons: 7, MAPE: 8.610905187402203\n",
            "Output: [2, 2, 1, 3, 2, 2, 1, 3, 1, 2, 3, 1, 2, 2, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 2, 1, 3, 2, 1, 1, 2, 1, 2, 3, 3, 2, 1, 1]\n",
            "True : [2 2 1 3 2 2 1 3 1 2 3 1 2 2 1 1 1 2 3 3 3 1 1 1 1 3 3 3 1 1 1 2 1 3 3 1 1\n",
            " 2 1 2 3 3 2 1 1]\n",
            "Accuracy with 7 hidden neurons: 0.9777777777777777\n",
            "--------------------------------------------------\n",
            "Waktu eksekusi: 0.008415937423706055 detik\n",
            "Hidden Neurons: 10, MAPE: 8.038901804488669\n",
            "Output: [2, 2, 1, 3, 2, 2, 1, 3, 1, 2, 3, 1, 2, 2, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 2, 1, 3, 2, 1, 1, 2, 1, 2, 3, 3, 2, 1, 1]\n",
            "True : [2 2 1 3 2 2 1 3 1 2 3 1 2 2 1 1 1 2 3 3 3 1 1 1 1 3 3 3 1 1 1 2 1 3 3 1 1\n",
            " 2 1 2 3 3 2 1 1]\n",
            "Accuracy with 10 hidden neurons: 0.9777777777777777\n",
            "--------------------------------------------------\n",
            "Waktu eksekusi: 0.002957582473754883 detik\n",
            "Hidden Neurons: 30, MAPE: 193.79444508314398\n",
            "Output: [5, 5, 5, 6, 5, 5, 5, 6, 5, 5, 6, 5, 5, 5, 5, 5, 4, 5, 6, 6, 6, 5, 5, 5, 5, 6, 6, 6, 4, 5, 5, 5, 5, 6, 5, 5, 4, 5, 5, 5, 6, 6, 5, 5, 5]\n",
            "True : [2 2 1 3 2 2 1 3 1 2 3 1 2 2 1 1 1 2 3 3 3 1 1 1 1 3 3 3 1 1 1 2 1 3 3 1 1\n",
            " 2 1 2 3 3 2 1 1]\n",
            "Accuracy with 30 hidden neurons: 0.0\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. (a) Lakukan klasifikasi menggunakan dataset Iris seperti pada contoh di atas dengan menggunakan metode Backpropagation dengan parameter berikut:  \n",
        "\n",
        "*   Rasio data latih: 70% dan data uji: 30%\n",
        "*   Hidden neuron = 3\n",
        "*   Max epoch = 100\n",
        "*   Learning rate = 0.1\n",
        "*   Max error = 0.5\n",
        "\n",
        "Catat hasil klasifikasi dengan menggunakan metode Backpropagation.\n"
      ],
      "metadata": {
        "id": "w5jampHzTwiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def onehot_enc(lbl, min_val=0):\n",
        "    mi = min(lbl)\n",
        "    enc = np.full((len(lbl), max(lbl) - mi + 1), min_val, np.int8)\n",
        "\n",
        "    for i, x in enumerate(lbl):\n",
        "        enc[i, x - mi] = 1\n",
        "    return enc\n",
        "\n",
        "def onehot_dec(enc, mi=0):\n",
        "    return [np.argmax(e) + mi for e in enc]"
      ],
      "metadata": {
        "id": "ZBJf_6HgXh1z"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sig(X):\n",
        "    return [1 / (1 + np.exp(-x)) for x in X]\n",
        "\n",
        "def sigd(X):\n",
        "    output = []\n",
        "\n",
        "    for i, x in enumerate(X):\n",
        "        s = sig([x])[0]\n",
        "        output.append(s * (1 - s))\n",
        "    return output"
      ],
      "metadata": {
        "id": "pFZrFpQfXlRX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def bp_fit(X, target, layer_conf, max_epoch, max_error=0.1, learn_rate=0.1, print_per_epoch=100):\n",
        "    np.random.seed(1)\n",
        "\n",
        "    nin = [np.empty(i) for i in layer_conf]\n",
        "\n",
        "    n = [np.empty(j + 1) if i < len(layer_conf) - 1 else np.empty(j)\n",
        "         for i, j in enumerate(layer_conf)]\n",
        "\n",
        "    w = [np.random.rand(layer_conf[i] + 1, layer_conf[i + 1])\n",
        "         for i in range(len(layer_conf) - 1)]\n",
        "\n",
        "    dw = [np.empty((layer_conf[i] + 1, layer_conf[i + 1]))\n",
        "          for i in range(len(layer_conf) - 1)]\n",
        "\n",
        "    d = [np.empty(s) for s in layer_conf[1:]]\n",
        "    din = [np.empty(s) for s in layer_conf[1:-1]]\n",
        "\n",
        "    epoch = 0\n",
        "    mse = 1\n",
        "\n",
        "\n",
        "    for i in range(0, len(n) - 1):\n",
        "        n[i][-1] = 1\n",
        "\n",
        "    while (max_epoch == -1 or epoch < max_epoch) and mse > max_error:\n",
        "        epoch += 1\n",
        "        mse = 0\n",
        "\n",
        "        for r in range(len(X)):\n",
        "            n[0][:-1] = X[r]\n",
        "\n",
        "            for L in range(1, len(layer_conf)):\n",
        "                nin[L] = np.dot(n[L - 1], w[L - 1])\n",
        "                n[L][:len(nin[L])] = sig(nin[L])\n",
        "\n",
        "            e = target[r] - n[-1]\n",
        "            mse += sum(e ** 2)\n",
        "            d[-1] = e * sigd(nin[-1])\n",
        "            dw[-1] = learn_rate * d[-1] * n[-2].reshape((-1, 1))\n",
        "\n",
        "            for L in range(len(layer_conf) - 1, 1, -1):\n",
        "                din[L - 2] = np.dot(d[L - 1], np.transpose(w[L - 1][:-1]))\n",
        "                d[L - 2] = din[L - 2] * sigd(nin[L - 1])\n",
        "                dw[L - 2] = learn_rate * d[L - 2] * n[L - 2].reshape((-1, 1))\n",
        "\n",
        "            for i in range(len(w)):\n",
        "                w[i] += dw[i]\n",
        "\n",
        "        mse /= len(X)\n",
        "\n",
        "        if print_per_epoch > -1 and epoch % print_per_epoch == 0:\n",
        "            print(f'Epoch {epoch}, MSE: {mse}')\n",
        "\n",
        "    return w, epoch, mse"
      ],
      "metadata": {
        "id": "OtDm76DgUZWV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bp_predict(X, w):\n",
        "    n = [np.empty(len(i)) for i in w]\n",
        "    nin = [np.empty(len(i[0])) for i in w]\n",
        "    predict = []\n",
        "\n",
        "    n.append(np.empty(len(w[-1][0])))\n",
        "\n",
        "    for x in X:\n",
        "        n[0][:-1] = x\n",
        "\n",
        "        for L in range(0, len(w)):\n",
        "            nin[L] = np.dot(n[L], w[L])\n",
        "            n[L + 1][:len(nin[L])] = sig(nin[L])\n",
        "\n",
        "        predict.append(n[-1].copy())\n",
        "\n",
        "    return predict"
      ],
      "metadata": {
        "id": "mVJCGCpAXQyN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = minmax_scale(iris.data)\n",
        "Y = onehot_enc(iris.target)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.3,random_state=1)\n",
        "w, ep, mse = bp_fit(X_train, y_train, layer_conf=(4, 3, 3), learn_rate=.1, max_epoch=100, max_error=.1, print_per_epoch=25)\n",
        "\n",
        "print(f'Epochs: {ep}, MSE: {mse}')\n",
        "\n",
        "predict = bp_predict(X_test, w)\n",
        "predict = onehot_dec(predict)\n",
        "y_test = onehot_dec(y_test)\n",
        "\n",
        "accuracy = accuracy_score(predict, y_test)\n",
        "print('Output:', predict)\n",
        "print('True :', y_test)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMZExV8aXS6s",
        "outputId": "669f78a7-4b28-4662-97f7-b4d914089211"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, MSE: 0.4573000553790559\n",
            "Epoch 50, MSE: 0.321272689922169\n",
            "Epoch 75, MSE: 0.2668003450939322\n",
            "Epoch 100, MSE: 0.19045841193641896\n",
            "Epochs: 100, MSE: 0.19045841193641896\n",
            "Output: [0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1, 2, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2, 1]\n",
            "True : [0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2, 1]\n",
            "Accuracy: 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  (b) Lakukanlah klasifikasi menggunakan dataset Iris seperti pada contoh diatas dengan menggunakan metode ELM dengan parameter berikut:\n",
        "\n",
        "*   Rasio data latih: 70% dan data uji: 30%\n",
        "*   Hidden neuron = 3\n",
        "\n",
        "Catat hasil klasifikasi dengan menggunakan metode ELM.\n"
      ],
      "metadata": {
        "id": "_QXbwlXIUZ3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = minmax_scale(iris.data)\n",
        "Y = iris.target\n",
        "Y += 1\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.3)\n",
        "\n",
        "W, b, mape = elm_fit(X_train, y_train, 3)\n",
        "print('MAPE:', mape)\n",
        "output = elm_predict(X_test, W, b, round_output=True)\n",
        "accuracy = accuracy_score(output, y_test)\n",
        "\n",
        "print('Output:', output)\n",
        "print('True :', y_test)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT_egEd6UmQ9",
        "outputId": "f2366f71-6b7c-48fb-fd3c-5a6a1abdf882"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waktu eksekusi: 0.0002880096435546875 detik\n",
            "MAPE: 8.490013218474981\n",
            "Output: [3, 1, 3, 2, 2, 3, 2, 2, 1, 1, 3, 1, 2, 3, 2, 2, 3, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 2, 3, 2, 2, 1, 3, 3, 1, 2, 1, 1, 3, 2, 1, 1, 2, 2, 2]\n",
            "True : [3 1 3 2 2 3 2 2 1 1 3 1 2 3 2 2 3 1 1 1 1 3 1 1 1 3 1 2 3 2 2 1 3 3 1 2 1\n",
            " 1 3 2 1 1 3 2 2]\n",
            "Accuracy: 0.9555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kesimpulan"
      ],
      "metadata": {
        "id": "htl3bFbHIvIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Apa yang dimaksud Single Layer Feedforward Neural Networks (SLFNs) dalam Extreme Learning Machine?\n",
        "- SLFNs adalah jaringan saraf yang memiliki satu lapisan tersembunyi dengan sejumlah neuron yang menerima input dan memberikan output langsung ke lapisan keluaran tanpa lapisan tersembunyi tambahan. Pada ELM, bobot antara input dan lapisan tersembunyi diatur secara acak, dan hanya bobot antara lapisan tersembunyi dan lapisan keluaran yang disesuaikan. SLFNs dalam ELM memungkinkan pelatihan yang sangat cepat dibandingkan dengan metode tradisional.\n",
        "\n",
        "2. Apa yang membedakan antara Extreme Learning Machine dengan Backpropagation?\n",
        "- Proses Pelatihan: Dalam ELM, bobot input dan bias lapisan tersembunyi diatur secara acak, sementara Backpropagation menghitung bobot dan bias menggunakan metode penurunan gradien.\n",
        "- Kecepatan: ELM jauh lebih cepat karena bobot antara lapisan input dan lapisan tersembunyi tidak diperbarui selama pelatihan. Backpropagation memerlukan waktu lebih lama karena harus melakukan iterasi berulang untuk mengurangi kesalahan.\n",
        "- Penyesuaian Bobot: ELM menganggap bobot lapisan input sebagai acak dan hanya menyesuaikan bobot lapisan keluaran dengan sekali perhitungan, sedangkan Backpropagation menyesuaikan semua bobot menggunakan algoritma iteratif untuk mencapai konvergensi pada bobot optimal.\n",
        "\n",
        "3. Metode manakah yang paling baik? Jelaskan!\n",
        "- Dalam kasus ini, Backpropagation memberikan hasil klasifikasi yang sedikit lebih baik dan lebih stabil daripada ELM, terutama saat jumlah neuron tersembunyi meningkat.\n",
        "Namun, ELM lebih cepat dalam hal eksekusi dan mampu memberikan hasil yang cukup baik dengan akurasi mendekati Backpropagation.\n",
        "Pilihan terbaik antara ELM dan Backpropagation bergantung pada kebutuhan spesifik aplikasi. Jika diperlukan kecepatan tinggi tanpa banyak iterasi seperti dalam aplikasi real-time, ELM mungkin lebih baik. Jika akurasinya sangat penting dan waktu pelatihan tidak menjadi kendala, Backpropagation bisa menjadi pilihan yang lebih stabil dan akurat.\n"
      ],
      "metadata": {
        "id": "SLV54D1CIx0t"
      }
    }
  ]
}